{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "rel_mowa_df = pd.read_csv('/../data_mowa.csv', sep=';') # transcribed statements\n",
        "\n",
        "rel_pismo_df = pd.read_csv('/../data_pismo.csv', sep=';') # typed statements"
      ],
      "metadata": {
        "id": "Emqg36o4JX4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "\n",
        "all_texts = {} ; all_labels = {}\n",
        "\n",
        "fpath = '.../typed_statements/'\n",
        "\n",
        "all_labels['p'] = [] ; all_texts['p'] = []\n",
        "for index, row in rel_pismo_df.iterrows():\n",
        "  if row['id']+'.txt' in pisemne_files:\n",
        "    if row['credibility'] >= 2: all_labels['p'].append(1)\n",
        "    else: all_labels['p'].append(0)\n",
        "     \n",
        "    with codecs.open(fpath+row['id']+'.txt','r','utf8') as fr:\n",
        "      all_texts['p'].append ( fr.read() )\n",
        "\n",
        "print(len(all_texts['p']))\n",
        "\n",
        "\n",
        "mowa_fname_creds = {} ; mowa_fname_texts = {}\n",
        "\n",
        "fpath = '.../transcribed_statements/'\n",
        "\n",
        "all_labels['t'] = [] ; all_texts['t'] = []\n",
        "for index, row in rel_mowa_df.iterrows():\n",
        "  if row['id']+'.txt' in transkrypcje_files:\n",
        "    if row['credibility'] >= 2: all_labels['t'].append(1)\n",
        "    else: all_labels['t'].append(0)\n",
        "     \n",
        "    with codecs.open(fpath+row['id']+'.txt','r','utf8') as fr:\n",
        "      all_texts['t'].append ( fr.read() )\n",
        "\n",
        "print(len(all_texts['t']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb9rxD7PlGU6",
        "outputId": "3daf388c-9d11-4f25-d947-ad46b63f898c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "321\n",
            "318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Veracity prediction using the Universal Sentence Encoder (USE) and SVM\n",
        "\n"
      ],
      "metadata": {
        "id": "R0ukgRmYsolb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install tensorflow-gpu\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "!pip3 install tensorflow_text #>=2.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ippEVqz0sn9J",
        "outputId": "42c7067c-4422-436a-8c19-2bf646fdfdbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Collecting tensorflow<2.12,>=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 19 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (4.4.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 70.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.15.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (14.0.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.28.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.19.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.1.1)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 67.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.51.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2022.12.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.12.6 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import tensorflow_text\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
        "#embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
        "#embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/2\")\n"
      ],
      "metadata": {
        "id": "EZu0YdyztM_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute USE embeddings of each text:"
      ],
      "metadata": {
        "id": "is_AXlTOIcBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_embedded_texts = {}\n",
        "n=50\n",
        "\n",
        "for text_type in ['p', 't']:\n",
        "\n",
        "  all_embedded_texts[text_type] = []\n",
        "  chunks=[all_texts[text_type][i:i + n] for i in range(0, len(all_texts[text_type]), n)]  \n",
        "  for chunk in chunks:\n",
        "    all_embedded_texts[text_type].extend( embed(chunk).numpy() )\n"
      ],
      "metadata": {
        "id": "-tn-SrHQtP_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, LeaveOneOut\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import NuSVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "import pickle\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "\n",
        "#for kernel_type in ['rbf', 'linear']:\n",
        "kernel_type = 'rbf'\n",
        "\n",
        "use3_results = {}\n",
        "for text_type in ['p', 't']:\n",
        "  print(f\"text_type: {text_type} \")\n",
        "  embeddings = np.array(all_embedded_texts[text_type])\n",
        "  labels = np.array(all_labels[text_type])\n",
        "\n",
        "  use3_results[text_type] = []\n",
        "  true_labels = []\n",
        "  predicted_labels = []\n",
        "\n",
        "  foldnr=0\n",
        "  kf = KFold(n_splits=20, shuffle=True, random_state=42)\n",
        "  #kf = LeaveOneOut()\n",
        "  for train_index, test_index in kf.split(embeddings):\n",
        "\n",
        "    X_train, X_test = embeddings[train_index], embeddings[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "    clf = NuSVC(nu=0.5, kernel=kernel_type)\n",
        "\n",
        "    model = clf.fit(X_train, y_train.ravel())\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    use3_results[text_type].append( {'y_pred':predictions , 'y_true':y_test } )\n",
        "\n",
        "    predicted_labels.extend(predictions)\n",
        "    true_labels.extend(y_test)\n",
        "\n",
        "    foldnr += 1\n",
        "\n",
        "  print(classification_report(true_labels, predicted_labels, digits=2 ))\n",
        "\n",
        "  dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "  dummy_clf.fit(X_train, y_train.ravel())\n",
        "  print(f'MF baseline: {dummy_clf.score(X_train, y_train.ravel())}')\n",
        "\n",
        "  stat, p = wilcoxon(x=predicted_labels, y=true_labels)\n",
        "  print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "  # interpret\n",
        "  alpha = 0.05\n",
        "  if p > alpha:\n",
        "    print('Same distribution (fail to reject H0)')\n",
        "  else:\n",
        "    print('Different distribution (reject H0)')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5z8ArARtkWW",
        "outputId": "28474ddf-61d3-4b50-a7ea-c09eaa80f9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_type: p \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.53      0.55       153\n",
            "           1       0.60      0.65      0.63       168\n",
            "\n",
            "    accuracy                           0.60       321\n",
            "   macro avg       0.59      0.59      0.59       321\n",
            "weighted avg       0.59      0.60      0.59       321\n",
            "\n",
            "MF baseline: 0.5245901639344263\n",
            "Statistics=3799.000, p=0.219\n",
            "Same distribution (fail to reject H0)\n",
            "text_type: t \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.73      0.71       187\n",
            "           1       0.58      0.53      0.56       131\n",
            "\n",
            "    accuracy                           0.65       318\n",
            "   macro avg       0.64      0.63      0.63       318\n",
            "weighted avg       0.65      0.65      0.65       318\n",
            "\n",
            "MF baseline: 0.5841584158415841\n",
            "Statistics=2800.000, p=0.296\n",
            "Same distribution (fail to reject H0)\n"
          ]
        }
      ]
    }
  ]
}